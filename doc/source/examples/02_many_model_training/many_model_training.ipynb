{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce29a8bb",
   "metadata": {},
   "source": [
    "# Many Model Training with Ray Tune\n",
    "\n",
    "This template is a quickstart to using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) for batch inference. Ray Tune is one of many libraries under the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html). See [this blog post](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray) for more information on the benefits of performing many model training with Ray!\n",
    "\n",
    "This template walks through time-series forecasting using `statsforecast`, but the framework and data format can be swapped out easily -- they are there just to help you build your own application!\n",
    "\n",
    "At a high level, this template will:\n",
    "\n",
    "1. [Define the training function for a single partition of data.](https://docs.ray.io/en/latest/tune/tutorials/tune-run.html)\n",
    "2. [Define a Tune search space to run training over many partitions of data.](https://docs.ray.io/en/latest/tune/tutorials/tune-search-spaces.html)\n",
    "3. [Extract the best model per dataset partition from the Tune experiment output.](https://docs.ray.io/en/latest/tune/examples/tune_analyze_results.html)\n",
    "\n",
    "> Slot in your code below wherever you see the ✂️ icon to build a many model training Ray application off of this template!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, AutoETS\n",
    "from pyarrow import parquet as pq\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e493d",
   "metadata": {},
   "source": [
    "> ✂️ Replace this value to change the number of data partitions you will use. This will be total the number of Tune trials you will run!\n",
    ">\n",
    "> Note that this template fits two models per data partition and reports the best performing one.\n",
    ">\n",
    "> Try starting with the recommended value in the table below:\n",
    "\n",
    "| Template Size | `NUM_DATA_PARTITIONS` |\n",
    "| ------------- | --------------------- |\n",
    "|Small-scale (single-node) | 50  |\n",
    "|Large-scale (multi-node)  | 1000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bfc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATA_PARTITIONS: int = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf104b9",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "If you're running the small-scale version of the template, try setting\n",
    "the number of trials to the recommended number of trials for the large-scale version.\n",
    "It'll be much slower, but you'll see the dramatic speedup once distributing the load\n",
    "to a multi-node Ray cluster in the large-scale version!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607aeb1c",
   "metadata": {},
   "source": [
    "> ✂️ Replace the following with your own data-loading and evaluation helper functions. (Or, just delete these!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91aafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m5_partition(unique_id: str) -> pd.DataFrame:\n",
    "    df = (\n",
    "        pq.read_table(\n",
    "            \"s3://anonymous@m5-benchmarks/data/train/target.parquet\",\n",
    "            columns=[\"item_id\", \"timestamp\", \"demand\"],\n",
    "            filters=[(\"item_id\", \"=\", unique_id)],\n",
    "        )\n",
    "        .to_pandas()\n",
    "        .rename(columns={\"item_id\": \"unique_id\", \"timestamp\": \"ds\", \"demand\": \"y\"})\n",
    "    )\n",
    "    df[\"unique_id\"] = df[\"unique_id\"].astype(str)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def evaluate_cross_validation(df, metric):\n",
    "    models = df.drop(columns=[\"ds\", \"cutoff\", \"y\"]).columns.tolist()\n",
    "    evals = []\n",
    "    for model in models:\n",
    "        eval_ = (\n",
    "            df.groupby([\"unique_id\", \"cutoff\"])\n",
    "            .apply(lambda x: metric(x[\"y\"].values, x[model].values))\n",
    "            .to_frame()\n",
    "        )\n",
    "        eval_.columns = [model]\n",
    "        evals.append(eval_)\n",
    "    evals = pd.concat(evals, axis=1)\n",
    "    evals = evals.groupby([\"unique_id\"]).mean(numeric_only=True)\n",
    "    evals[\"best_model\"] = evals.idxmin(axis=1)\n",
    "    return evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf544b9",
   "metadata": {},
   "source": [
    "> ✂️ Replace this with your own training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3884c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = [AutoARIMA, AutoETS]\n",
    "n_windows = 1\n",
    "\n",
    "\n",
    "def train_fn(config: dict):\n",
    "    data_partition_id = config[\"data_partition_id\"]\n",
    "    train_df = get_m5_partition(data_partition_id)\n",
    "\n",
    "    models = [model_cls() for model_cls in model_classes]\n",
    "    forecast_horizon = 4\n",
    "\n",
    "    sf = StatsForecast(\n",
    "        df=train_df,\n",
    "        models=models,\n",
    "        freq=\"D\",\n",
    "        n_jobs=n_windows * len(models),\n",
    "    )\n",
    "    cv_df = sf.cross_validation(\n",
    "        h=forecast_horizon,\n",
    "        step_size=forecast_horizon,\n",
    "        n_windows=n_windows,\n",
    "    )\n",
    "\n",
    "    eval_df = evaluate_cross_validation(df=cv_df, metric=mean_squared_error)\n",
    "    best_model = eval_df[\"best_model\"][data_partition_id]\n",
    "    forecast_mse = eval_df[best_model][data_partition_id]\n",
    "\n",
    "    # Report the best-performing model and its corresponding eval metric.\n",
    "    session.report({\"forecast_mse\": forecast_mse, \"best_model\": best_model})\n",
    "\n",
    "\n",
    "trainable = train_fn\n",
    "trainable = tune.with_resources(\n",
    "    trainable, resources={\"CPU\": len(model_classes) * n_windows}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69204f6",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`tune.with_resources` is used at the end to specify the number of resources to assign *each trial*.\n",
    "Feel free to change this to the resources required by your application! You can also comment out the `tune.with_resources` block to assign `1 CPU` (the default) to each trial.\n",
    "\n",
    "Note that this is purely for Tune to know how many trials to schedule concurrently -- setting the number of CPUs does not actually enforce any kind of resource isolation!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5d1ab",
   "metadata": {},
   "source": [
    "> ✂️ Replace this with your desired hyperparameter search space!\n",
    ">\n",
    "> For example, this template searches over the data partition ID to train a model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partitions = list(pd.read_csv(\"item_ids.csv\")[\"item_id\"])\n",
    "param_space = {\n",
    "    \"data_partition_id\": tune.grid_search(data_partitions[:NUM_DATA_PARTITIONS]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6de04",
   "metadata": {},
   "source": [
    "Run many model training using Ray Tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ea2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(trainable, param_space=param_space)\n",
    "result_grid = tuner.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0340b",
   "metadata": {},
   "source": [
    "> ✂️ Replace the metric and mode below with the metric you reported in your training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result = result_grid[0]\n",
    "sample_result.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56525258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "265d195fda5292fe8f69c6e37c435a5634a1ed3b6799724e66a975f68fa21517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
