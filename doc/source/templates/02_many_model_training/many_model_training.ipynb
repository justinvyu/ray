{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98e0d4f3",
   "metadata": {},
   "source": [
    "# Scaling Many Model Training with Ray Tune\n",
    "\n",
    "This template walks through time-series forecasting using `statsforecast`, but the framework and data format can be swapped out easily -- they are there just to help you build your own application!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e65f8d",
   "metadata": {},
   "source": [
    "> Slot in your code below wherever you see the ✂️ icon to build a many model training Ray application off of this template!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c56bb4d0",
   "metadata": {},
   "source": [
    "## Set up the dependencies\n",
    "\n",
    "There are two sets of dependencies that we'll set up.\n",
    "\n",
    "### Set up local dependencies\n",
    "\n",
    "The first set contains any dependencies that are needed locally by this notebook to *launch* the training job.\n",
    "\n",
    "Install the dependencies with the following command:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7ffc83e",
   "metadata": {},
   "source": [
    "### Set up runtime dependencies\n",
    "\n",
    "The second set contains dependencies that are required by the training job itself.\n",
    "\n",
    "Later on, we define a function that implements our custom training logic.\n",
    "This example uses Ray Tune, which will package up this training function and execute it somewhere in our Ray cluster --\n",
    "possibly on a different node than the node this notebook is running on.\n",
    "Therefore, a dependency installed here locally may not be accessible to our training code at runtime.\n",
    "\n",
    "We can use a [Ray Runtime Environment](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments)\n",
    "to dynamically set up dependencies, which enables us to import the specified dependencies\n",
    "from within our training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"pyarrow==11.0.0\",\n",
    "            \"scikit-learn==1.2.2\",\n",
    "            \"statsforecast==1.5.0\",\n",
    "        ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9dc54",
   "metadata": {},
   "source": [
    "## Define the custom training function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8fc83d0",
   "metadata": {},
   "source": [
    "> ✂️ Replace this value to change the number of data partitions you will use (<= 5000 for this dataset). This will be total the number of Tune trials you will run!\n",
    ">\n",
    "> Note that this template fits two models per data partition and reports the best performing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390c232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_DATA_PARTITIONS: int = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f3d16",
   "metadata": {},
   "source": [
    "> ✂️ Replace the following with your own data-loading and evaluation helper functions. (Or, just delete these!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b14061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m5_partition(unique_id: str) -> pd.DataFrame:\n",
    "    from pyarrow import parquet as pq\n",
    "\n",
    "    df = (\n",
    "        pq.read_table(\n",
    "            \"s3://anonymous@m5-benchmarks/data/train/target.parquet\",\n",
    "            columns=[\"item_id\", \"timestamp\", \"demand\"],\n",
    "            filters=[(\"item_id\", \"=\", unique_id)],\n",
    "        )\n",
    "        .to_pandas()\n",
    "        .rename(columns={\"item_id\": \"unique_id\", \"timestamp\": \"ds\", \"demand\": \"y\"})\n",
    "    )\n",
    "    df[\"unique_id\"] = df[\"unique_id\"].astype(str)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def evaluate_cross_validation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    models = df.drop(columns=[\"ds\", \"cutoff\", \"y\"]).columns.tolist()\n",
    "    evals = []\n",
    "    for model in models:\n",
    "        eval_ = (\n",
    "            df.groupby([\"unique_id\", \"cutoff\"])\n",
    "            .apply(lambda x: mean_squared_error(x[\"y\"].values, x[model].values))\n",
    "            .to_frame()\n",
    "        )\n",
    "        eval_.columns = [model]\n",
    "        evals.append(eval_)\n",
    "    evals = pd.concat(evals, axis=1)\n",
    "    evals = evals.groupby([\"unique_id\"]).mean(numeric_only=True)\n",
    "    evals[\"best_model\"] = evals.idxmin(axis=1)\n",
    "    return evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ee3ce",
   "metadata": {},
   "source": [
    "> ✂️ Replace this with your own training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(config: dict):\n",
    "    try:\n",
    "        from statsforecast import StatsForecast\n",
    "        from statsforecast.models import AutoARIMA, AutoETS\n",
    "    except ImportError as e:\n",
    "        raise RuntimeError(\"Did you set a runtime env to install dependencies?\") from e\n",
    "\n",
    "    data_partition_id = config[\"data_partition_id\"]\n",
    "    train_df = get_m5_partition(data_partition_id)\n",
    "\n",
    "    models = [AutoARIMA(), AutoETS()]\n",
    "    n_windows = 1\n",
    "    forecast_horizon = 4\n",
    "\n",
    "    sf = StatsForecast(\n",
    "        df=train_df,\n",
    "        models=models,\n",
    "        freq=\"D\",\n",
    "        n_jobs=n_windows * len(models),\n",
    "    )\n",
    "    cv_df = sf.cross_validation(\n",
    "        h=forecast_horizon,\n",
    "        step_size=forecast_horizon,\n",
    "        n_windows=n_windows,\n",
    "    )\n",
    "\n",
    "    eval_df = evaluate_cross_validation(df=cv_df, metric=mean_squared_error)\n",
    "    best_model = eval_df[\"best_model\"][data_partition_id]\n",
    "    forecast_mse = eval_df[best_model][data_partition_id]\n",
    "\n",
    "    # Report the best-performing model and its corresponding eval metric.\n",
    "    session.report({\"forecast_mse\": forecast_mse, \"best_model\": best_model})\n",
    "\n",
    "\n",
    "trainable = train_fn\n",
    "trainable = tune.with_resources(trainable, resources={\"CPU\": 2 * 1})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "301c7c58",
   "metadata": {},
   "source": [
    "`tune.with_resources` is used at the end to specify the number of resources to assign *each trial*.\n",
    "Feel free to change this to the resources required by your application! You can also comment out the `tune.with_resources` block to assign `1 CPU` (the default) to each trial.\n",
    "\n",
    "Note that this is purely for Tune to know how many trials to schedule concurrently -- setting the number of CPUs does not actually enforce any kind of resource isolation!\n",
    "In this template, `statsforecast` runs cross validation in parallel with M models * N temporal cross-validation windows (e.g. 2 * 1).\n",
    "\n",
    "See [Ray Tune's guide on assigning resources](https://docs.ray.io/en/latest/tune/tutorials/tune-resources.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89741e7a",
   "metadata": {},
   "source": [
    "> ✂️ Replace this with your desired hyperparameter search space!\n",
    ">\n",
    "> For example, this template searches over the data partition ID to train a model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the list of item ids used to partition the dataset.\n",
    "data_partitions = list(\n",
    "    pd.read_csv(\n",
    "        \"https://air-example-data.s3.us-west-2.amazonaws.com/m5_benchmarks_item_ids.csv\"\n",
    "    )[\"item_id\"]\n",
    ")\n",
    "if NUM_DATA_PARTITIONS > len(data_partitions):\n",
    "    print(f\"There are only {len(data_partitions)} partitions!\")\n",
    "\n",
    "param_space = {\n",
    "    \"data_partition_id\": tune.grid_search(data_partitions[:NUM_DATA_PARTITIONS]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4dd3e",
   "metadata": {},
   "source": [
    "Run many model training using Ray Tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(trainable, param_space=param_space)\n",
    "result_grid = tuner.fit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba1a07d0",
   "metadata": {},
   "source": [
    "View the reported results of all trials as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baa29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = result_grid.get_dataframe()\n",
    "results_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c67dfdb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This template is a quickstart to using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) for many model training. Ray Tune is one of many libraries under the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html). See [this blog post](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray) for more information on the benefits of performing many model training with Ray!\n",
    "\n",
    "At a high level, this template showed how to do the following:\n",
    "\n",
    "1. [Define the training function for a single partition of data.](https://docs.ray.io/en/latest/tune/tutorials/tune-run.html)\n",
    "2. [Define a Tune search space to run training over many partitions of data.](https://docs.ray.io/en/latest/tune/tutorials/tune-search-spaces.html)\n",
    "3. [Extract the best model per dataset partition from the Tune experiment output.](https://docs.ray.io/en/latest/tune/examples/tune_analyze_results.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf96002",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "265d195fda5292fe8f69c6e37c435a5634a1ed3b6799724e66a975f68fa21517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
