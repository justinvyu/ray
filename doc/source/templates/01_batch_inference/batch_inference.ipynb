{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fbc3e3c",
   "metadata": {},
   "source": [
    "# Scaling Batch Inference with Ray Data\n",
    "\n",
    "This template walks through GPU batch inference on a subset of the Imagenet dataset using a PyTorch ResNet model.\n",
    "\n",
    "The framework and data format used in this template can be easily replaced to suit your own application!\n",
    "\n",
    "> Slot in your code below wherever you see the ✂️ icon to build off of this template!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68bd5f9c",
   "metadata": {},
   "source": [
    "## Set up the dependencies\n",
    "\n",
    "Since we're running on a distributed Ray cluster with multiple nodes, we need to first\n",
    "set up dependencies so that our batch inference workers can access all the required packages.\n",
    "\n",
    "There are two sets of dependencies that we'll set up.\n",
    "\n",
    "### Set up local dependencies\n",
    "\n",
    "The first set contains any dependencies that are needed locally by this notebook.\n",
    "Install the dependencies with the following command:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8724568",
   "metadata": {},
   "source": [
    "### Set up runtime dependencies\n",
    "\n",
    "The second set contains dependencies that are required by each worker.\n",
    "\n",
    "Later on, we define a class that implements our custom model initialization and inference logic.\n",
    "Ray Data will run batch inference on many workers using copies of this class somewhere in our Ray cluster.\n",
    "It's important to note that the workers may live on a different node than the one running this notebook.\n",
    "Therefore, a dependency installed here locally may not be accessible to our training code at runtime.\n",
    "\n",
    "To address this, we can specify a [Ray Runtime Environment](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments)\n",
    "to dynamically set up dependencies, which enables us to import the specified dependencies\n",
    "on the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459342ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(runtime_env={\"pip\": [\"torch\", \"torchvision\"]})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0edfc6e2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b6f2352",
   "metadata": {},
   "source": [
    "> ✂️ Replace this function with logic to load your own data with Ray Data.\n",
    ">\n",
    "> See [the Ray Data guide on creating datasets](https://docs.ray.io/en/latest/data/creating-datasets.html) to learn how to create a dataset based on the data type and how file storage format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ray_dataset():\n",
    "    from ray.data.datasource.partitioning import Partitioning\n",
    "\n",
    "    s3_uri = \"s3://anonymous@air-example-data-2/imagenette2/val/\"\n",
    "    partitioning = Partitioning(\"dir\", field_names=[\"class\"], base_dir=s3_uri)\n",
    "    ds = ray.data.read_images(\n",
    "        s3_uri, size=(256, 256), partitioning=partitioning, mode=\"RGB\"\n",
    "    )\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_ray_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = [sample[\"image\"] for sample in ds.take(5)]\n",
    "\n",
    "_, axs = plt.subplots(1, 5, figsize=(10, 5))\n",
    "\n",
    "for i, image in enumerate(sample_images):\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis(\"off\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7671aa0",
   "metadata": {},
   "source": [
    "## Preprocess the dataset\n",
    "\n",
    "We may need to preprocess the dataset before passing it to the model.\n",
    "This just amounts to writing a function that performs the preprocessing logic, and then\n",
    "applying the function to the entire dataset with a call to `map_batches`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d01e3c",
   "metadata": {},
   "source": [
    "> ✂️ Replace this function with your own data preprocessing logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652121bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "    import torch\n",
    "    from torchvision import transforms\n",
    "\n",
    "    def to_tensor(batch: np.ndarray) -> torch.Tensor:\n",
    "        tensor = torch.as_tensor(batch, dtype=torch.float)\n",
    "        # (B, H, W, C) -> (B, C, H, W)\n",
    "        tensor = tensor.permute(0, 3, 1, 2).contiguous()\n",
    "        # [0., 255.] -> [0., 1.]\n",
    "        tensor = tensor.div(255)\n",
    "        return tensor\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Lambda(to_tensor),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    return {\"image\": transform(batch[\"image\"]).numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map_batches(preprocess, batch_format=\"numpy\")\n",
    "\n",
    "print(\"Dataset schema:\\n\", ds.schema())\n",
    "print(\"Number of images:\", ds.count())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaa3653b",
   "metadata": {},
   "source": [
    "## Set up your model for inference\n",
    "\n",
    "Define a class that loads the model on initialization, and also performs inference with the loaded model whenever the class is called (by implementing `__call__`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad059e54",
   "metadata": {},
   "source": [
    "> ✂️ Replace parts of this callable class with your own model initialization and inference logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cac828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictCallable:\n",
    "    def __init__(self):\n",
    "        # <Replace this with your own model initialization>\n",
    "        import torch\n",
    "        from torchvision import models\n",
    "        from torchvision.models import ResNet152_Weights\n",
    "\n",
    "        self.model = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        # <Replace this with your own model inference logic>\n",
    "        import torch\n",
    "\n",
    "        input_data = torch.as_tensor(batch[\"image\"], device=self.device)\n",
    "        with torch.inference_mode():\n",
    "            pred = self.model(input_data)\n",
    "        return {\"predicted_class_index\": pred.argmax(dim=1).detach().cpu().numpy()}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d63f352",
   "metadata": {},
   "source": [
    "## Run batch inference\n",
    "\n",
    "We'll first configure the number of workers and the resource requirements of each worker.\n",
    "\n",
    "These defaults will assume that your cluster has 4 GPUs available.\n",
    "Be sure to stay within the resource constraints of your Ray Cluster if autoscaling is not enabled.\n",
    "\n",
    "`NUM_GPUS_PER_WORKER` can be a fractional amount! This will leverage Ray's fractional resource allocation, which means you can schedule multiple batch inference workers to use the same GPU, assuming that the models can all fit in GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49681f-baf0-4ed8-9740-5c4e38744311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS: int = 4\n",
    "NUM_GPUS_PER_WORKER: float = 1  # 0 <= NUM_GPUS_PER_WORKER <= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419658c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_WORKERS * NUM_GPUS_PER_WORKER > ray.available_resources()[\"GPU\"]:\n",
    "    print(\n",
    "        \"Your cluster does not currently have enough resources to run with these settings. \"\n",
    "        \"Consider decreasing the number of workers, or decreasing the resources needed \"\n",
    "        \"per worker.\"\n",
    "    )\n",
    "\n",
    "assert (\n",
    "    0 <= NUM_GPUS_PER_WORKER <= 1\n",
    "), \"`NUM_GPUS_PER_WORKER` must be within the range [0, 1]\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d170d2b",
   "metadata": {},
   "source": [
    "You can check the available resources in your Ray Cluster with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89dff216",
   "metadata": {},
   "source": [
    "Now, use Ray Data to perform batch inference using `NUM_WORKERS` copies of the `PredictCallable` class you defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ds.map_batches(\n",
    "    PredictCallable,\n",
    "    batch_size=128,\n",
    "    compute=ray.data.ActorPoolStrategy(\n",
    "        # Fix the number of batch inference workers to `NUM_WORKERS`.\n",
    "        min_size=NUM_WORKERS,\n",
    "        max_size=NUM_WORKERS,\n",
    "    ),\n",
    "    num_gpus=NUM_GPUS_PER_WORKER,\n",
    "    batch_format=\"numpy\",\n",
    ")\n",
    "\n",
    "preds = predictions.materialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c81c9",
   "metadata": {},
   "source": [
    "See the appendix for more information about setting `min_size` and `max_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c48946",
   "metadata": {},
   "source": [
    "## View the predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2565ba08",
   "metadata": {},
   "source": [
    "Show the first few predictions, which will show the predicted class labels of the images shown earlier! These first few predictions should show index 0, which maps to the class label `\"tench\"` (a type of fish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d606556",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.take(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ec67e8",
   "metadata": {},
   "source": [
    "Shard the predictions into a few partitions, and save each partition to a file.\n",
    "\n",
    "This currently saves to the local filesystem under a temporary directory, but you could also save to a cloud bucket (e.g., `s3://predictions-bucket`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1887e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shards = 3\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "predictions.repartition(num_shards).write_parquet(temp_dir)\n",
    "print(f\"Predictions saved to `{temp_dir}`!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b7b5d91",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This template used [Ray Data](https://docs.ray.io/en/latest/data/dataset.html) to scale out batch inference. Ray Data is one of many libraries under the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html). See [this blog post](https://www.anyscale.com/blog/model-batch-inference-in-ray-actors-actorpool-and-datasets) for more details on batch inference with Ray!\n",
    "\n",
    "At a high level, this template showed how to:\n",
    "1. [Load your dataset using Ray Data.](https://docs.ray.io/en/latest/data/loading-data.html)\n",
    "2. [Preprocess your dataset before feeding it to your model.](https://docs.ray.io/en/latest/data/transforming-data.html)\n",
    "3. [Initialize your model and perform inference on a shard of your dataset with a remote actor.](https://docs.ray.io/en/latest/data/transforming-data.html#reduce-setup-overheads-using-actors)\n",
    "4. [Save your prediction results.](https://docs.ray.io/en/latest/data/api/input_output.html)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f5a4257",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "\n",
    "#### Automatically determine the number of workers\n",
    "\n",
    "Play around with the `min_size` and `max_size` parameters to enable Ray Data to scale the number of workers based on the dataset size.\n",
    "For example, try commenting out `max_size`. This will start with `min_size` workers, then spin up as many new workers as needed (until the cluster runs out of resources to assign)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1658235",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "265d195fda5292fe8f69c6e37c435a5634a1ed3b6799724e66a975f68fa21517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
