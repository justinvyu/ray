{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f260280-af7b-4d8e-98bc-d3a8b3a9df43",
   "metadata": {},
   "source": [
    "# Many Model Training with Ray Tune\n",
    "\n",
    "This template is a quickstart to using [Ray Tune](todo) for batch inference. Ray Tune is one of many libraries under the [Ray AI Runtime](air). See [this blog post](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray) for more information on the benefits of performing many model training with Ray!\n",
    "\n",
    "This template walks through time-series forecasting using `sklearn`, but the framework and data format can be swapped out easily -- they are there just to help you build your own application!\n",
    "\n",
    "At a high level, this template will:\n",
    "\n",
    "\n",
    "> Slot in your own code below with the ✂️ icon to build a many model training Ray application of your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9382de4-22d0-4de2-83c4-2ecab7911e4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsforecast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsforecast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatsForecast\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ETS, AutoARIMA, _TS\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parquet \u001b[38;5;28;01mas\u001b[39;00m pq\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsforecast'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import ETS, AutoARIMA, _TS\n",
    "from pyarrow import parquet as pq\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import ray\n",
    "from ray import air, tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d088d86-28f9-4eda-8415-ab72383c1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m5_partition(unique_id: str) -> pd.DataFrame:\n",
    "    df = pq.read_table(\n",
    "        \"s3://anonymous@m5-benchmarks/data/train/target.parquet\",\n",
    "        columns=[\"item_id\", \"timestamp\", \"demand\"],\n",
    "        filters=[(\"item_id\", \"=\", unique_id)],\n",
    "    ).to_pandas().rename(\n",
    "        columns={\"item_id\": \"unique_id\", \"timestamp\": \"ds\", \"demand\": \"y\"}\n",
    "    )\n",
    "    df[\"unique_id\"] = df[\"unique_id\"].astype(str)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "    return df.dropna()\n",
    "\n",
    "train_df = get_m5_partition(\"FOODS_1_001_CA_1\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d488c7-cea4-487d-a086-684af9a50b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import Checkpoint, session\n",
    "\n",
    "def evaluate_cross_validation(df, metric):\n",
    "    models = df.drop(columns=['ds', 'cutoff', 'y']).columns.tolist()\n",
    "    evals = []\n",
    "    for model in models:\n",
    "        eval_ = df.groupby(['unique_id', 'cutoff']).apply(\n",
    "            lambda x: metric(x['y'].values, x[model].values)\n",
    "        ).to_frame()\n",
    "        eval_.columns = [model]\n",
    "        evals.append(eval_)\n",
    "    evals = pd.concat(evals, axis=1)\n",
    "    evals = evals.groupby(['unique_id']).mean(numeric_only=True)\n",
    "    evals['best_model'] = evals.idxmin(axis=1)\n",
    "    return evals\n",
    "\n",
    "def cross_validation(config: dict):\n",
    "    data_partition_id = config[\"data_partition_id\"]\n",
    "    train_df = get_m5_partition(data_partition_id)\n",
    "    \n",
    "    models = [\n",
    "        AutoARIMA(),\n",
    "        ETS(season_length=6, model: \"ZNA\"),\n",
    "        ETS(season_length=7, model: \"ZNA\"),\n",
    "        ETS(season_length=6, model: \"ZZZ\"),\n",
    "        ETS(season_length=7, model: \"ZZZ\"),\n",
    "    ]\n",
    "    forecast_horizon = 4\n",
    "    num_windows = 2\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        df=train_df,\n",
    "        models=models,\n",
    "        freq=\"D\",\n",
    "        n_jobs=n_windows,\n",
    "    )\n",
    "    cv_df = sf.cross_validation(\n",
    "        h=forecast_horizon,\n",
    "        step_size=forecast_horizon,\n",
    "        n_windows=n_windows,\n",
    "\n",
    "    )\n",
    "\n",
    "    eval_df = evaluate_cross_validation(df=cv_df, metric=mean_squared_error)\n",
    "    best_model = eval_df[\"best_model\"]\n",
    "    session.report({\"best_model\": best_model})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330a289-754e-49bd-bb51-b19fd0661130",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partitions = list(pd.read_csv(\"item_ids.csv\")[\"item_id\"])\n",
    "\n",
    "param_space = {\n",
    "    \"data_partition_id\": tune.grid_search(data_partitions[:100]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8109675-c870-432d-8d19-a21ab1377222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(cross_validation, param_space=param_space)\n",
    "result_grid = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
