{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "597c13c0",
   "metadata": {},
   "source": [
    "# Serving a Stable Diffusion Model with Ray Serve\n",
    "\n",
    "This template loads a pretrained stable diffusion model from HuggingFace and serves it to a local endpoint as a Ray Serve deployment.\n",
    "\n",
    "By the end, we'll have an application that generates images using stable diffusion for a given prompt!\n",
    "\n",
    "It'll look something like this:\n",
    "\n",
    "```\n",
    "Enter a prompt (or 'q' to quit):   twin peaks sf in basquiat painting style\n",
    "\n",
    "Generating image(s)...\n",
    "\n",
    "Generated 1 image(s) in 6.75 seconds to the directory: 58b298d9\n",
    "```\n",
    "\n",
    "![Example output](https://user-images.githubusercontent.com/3887863/221063452-3c5e5f6b-fc8c-410f-ad5c-202441cceb51.png)\n",
    "\n",
    "> Slot in your code below wherever you see the ✂️ icon to build off of this template!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c47d27bd",
   "metadata": {},
   "source": [
    "## Set up the dependencies\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42ca33dc",
   "metadata": {},
   "source": [
    "### Set up runtime dependencies\n",
    "\n",
    "First, we need to make sure that all code run remotely on our Ray cluster has access\n",
    "to certain dependencies.\n",
    "To do this, we can specify a [Ray Runtime Environment](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments)\n",
    "to dynamically set up runtime dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca638dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"accelerate==0.14.0\",\n",
    "            \"diffusers==0.15.1\",\n",
    "            \"numpy>=1.21.6,<=1.23.5\",\n",
    "            \"tensorboard>=2.11.2,<=2.12.0\",\n",
    "            \"torch>=1.13.0\",\n",
    "            \"transformers==4.28.1\",\n",
    "        ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7584fa81",
   "metadata": {},
   "source": [
    "### Set up local dependencies\n",
    "\n",
    "Next, we'll install dependencies that are needed locally by this notebook.\n",
    "Install the dependencies with the following command:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59842da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.responses import Response\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import ray\n",
    "from ray import serve\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "520ef4d7",
   "metadata": {},
   "source": [
    "## Deploy the Ray Serve application locally\n",
    "\n",
    "First, we define the Ray Serve application with the model loading and inference logic. This includes setting up:\n",
    "- The `/imagine` API endpoint that we query to generate the image.\n",
    "- The stable diffusion model loaded inside a Ray Serve Deployment.\n",
    "  We'll specify the *number of model replicas* to keep active in our Ray cluster. These model replicas can process incoming requests concurrently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6318ac",
   "metadata": {},
   "source": [
    "> ✂️ Replace these values to change the number of model replicas to serve, as well as the GPU resources required by each replica.\n",
    ">\n",
    "> With more model replicas, more images can be generated in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eca147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_REPLICAS: int = 4\n",
    "NUM_GPUS_PER_REPLICA: float = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_REPLICAS * NUM_GPUS_PER_REPLICA > ray.available_resources()[\"GPU\"]:\n",
    "    print(\n",
    "        \"Your cluster does not currently have enough resources to run with these settings. \"\n",
    "        \"Consider decreasing the number of workers, or decreasing the resources needed \"\n",
    "        \"per worker.\"\n",
    "    )\n",
    "\n",
    "assert (\n",
    "    0 <= NUM_GPUS_PER_REPLICA <= 1\n",
    "), \"`NUM_GPUS_PER_WORKER` must be within the range [0, 1]\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89eb3e2c",
   "metadata": {},
   "source": [
    "First, we define the Ray Serve Deployment, which will load a stable diffusion model and perform inference with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a02213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure each model replica to use the specified resources.\n",
    "ray_actor_options = {\n",
    "    \"num_gpus\": NUM_GPUS_PER_REPLICA,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "880b8593",
   "metadata": {},
   "source": [
    "> ✂️ Modify this block to load your own model, and change the `generate` method to perform your own online inference logic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(\n",
    "    ray_actor_options=ray_actor_options,\n",
    "    num_replicas=NUM_REPLICAS,\n",
    ")\n",
    "class StableDiffusionV2:\n",
    "    def __init__(self):\n",
    "        # <Replace with your own model loading logic>\n",
    "        try:\n",
    "            import torch\n",
    "            from diffusers import EulerDiscreteScheduler, StableDiffusionPipeline\n",
    "        except ImportError as e:\n",
    "            raise RuntimeError(\n",
    "                \"Did you set a runtime env to install dependencies?\"\n",
    "            ) from e\n",
    "\n",
    "        model_id = \"stabilityai/stable-diffusion-2\"\n",
    "        scheduler = EulerDiscreteScheduler.from_pretrained(\n",
    "            model_id, subfolder=\"scheduler\"\n",
    "        )\n",
    "        self.pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            model_id, scheduler=scheduler, revision=\"fp16\", torch_dtype=torch.float16\n",
    "        )\n",
    "        self.pipe = self.pipe.to(\"cuda\")\n",
    "\n",
    "    def generate(self, prompt: str, img_size: int = 776):\n",
    "        # <Replace with your own model inference logic>\n",
    "        assert len(prompt), \"prompt parameter cannot be empty\"\n",
    "        image = self.pipe(prompt, height=img_size, width=img_size).images[0]\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134aa54",
   "metadata": {},
   "source": [
    "Next, we'll define the actual API endpoint to live at `/imagine`.\n",
    "\n",
    "> ✂️ Modify this block to change the endpoint URL, response schema, and add any post-processing logic needed from your model output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@serve.deployment(num_replicas=1, route_prefix=\"/\")\n",
    "@serve.ingress(app)\n",
    "class APIIngress:\n",
    "    def __init__(self, diffusion_model_handle) -> None:\n",
    "        self.handle = diffusion_model_handle\n",
    "\n",
    "    @app.get(\n",
    "        \"/imagine\",\n",
    "        responses={200: {\"content\": {\"image/png\": {}}}},\n",
    "        response_class=Response,\n",
    "    )\n",
    "    async def generate(self, prompt: str, img_size: int = 776):\n",
    "        assert len(prompt), \"prompt parameter cannot be empty\"\n",
    "\n",
    "        image = await (await self.handle.generate.remote(prompt, img_size=img_size))\n",
    "\n",
    "        file_stream = BytesIO()\n",
    "        image.save(file_stream, \"PNG\")\n",
    "        return Response(content=file_stream.getvalue(), media_type=\"image/png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8916d",
   "metadata": {},
   "source": [
    "Now, we deploy the Ray Serve application locally at `http://localhost:8000`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2e244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entrypoint = APIIngress.bind(StableDiffusionV2.bind())\n",
    "port = 8000\n",
    "\n",
    "# Shutdown any existing Serve replicas, if they're still around.\n",
    "serve.shutdown()\n",
    "serve.run(entrypoint, port=port, name=\"serving_stable_diffusion_template\")\n",
    "print(\"Done setting up replicas! Now accepting requests...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757678cc",
   "metadata": {},
   "source": [
    "## Make requests to the endpoint\n",
    "\n",
    "Next, we'll build a simple client to submit prompts as HTTP requests to the local endpoint at `http://localhost:8000/imagine`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29193b",
   "metadata": {},
   "source": [
    "> ✂️ Replace this value to change the number of images to generate per prompt.\n",
    ">\n",
    "> Each image will be generated starting from a different set of random noise,\n",
    "> so you'll be able to see multiple options per prompt!\n",
    ">\n",
    "> Try starting with `NUM_IMAGES_PER_PROMPT` equal to `NUM_REPLICAS` from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac28e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_IMAGES_PER_PROMPT: int = NUM_REPLICAS\n",
    "\n",
    "# Control the output size: (IMAGE_SIZE, IMAGE_SIZE)\n",
    "# The stable diffusion model requires `IMAGE_SIZE` to be a multiple of 8.\n",
    "# NOTE: Generated image quality degrades rapidly if you reduce the size too much.\n",
    "IMAGE_SIZE: int = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b466230",
   "metadata": {},
   "source": [
    "> ✂️ You can choose to run this interactively, or submit a single `PROMPT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIVE: bool = False\n",
    "PROMPT = \"twin peaks sf in basquiat painting style\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "008976b5",
   "metadata": {},
   "source": [
    "Start the client script in the next few cells, and generate your first image!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"http://localhost:{port}/imagine\"\n",
    "\n",
    "\n",
    "@ray.remote(num_cpus=1)\n",
    "def generate_image(prompt):\n",
    "    req = {\"prompt\": prompt, \"img_size\": IMAGE_SIZE}\n",
    "    resp = requests.get(endpoint, params=req)\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def show_images(filenames):\n",
    "    fig, axs = plt.subplots(1, len(filenames), figsize=(4 * len(filenames), 4))\n",
    "    for i, filename in enumerate(filenames):\n",
    "        ax = axs if len(filenames) == 1 else axs[i]\n",
    "        ax.imshow(plt.imread(filename))\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        requests.get(endpoint, timeout=0.1)\n",
    "    except Exception as e:\n",
    "        raise RuntimeWarning(\n",
    "            \"Did you setup the Ray Serve model replicas with \"\n",
    "            \"`python server.py --num-replicas=...` in another terminal yet?\"\n",
    "        ) from e\n",
    "\n",
    "    generation_times = []\n",
    "    while True:\n",
    "        prompt = (\n",
    "            PROMPT\n",
    "            if not INTERACTIVE\n",
    "            else input(f\"\\nEnter a prompt (or 'q' to quit):  \")\n",
    "        )\n",
    "        if prompt.lower() == \"q\":\n",
    "            break\n",
    "\n",
    "        print(\"\\nGenerating image(s)...\\n\")\n",
    "        start = time.time()\n",
    "\n",
    "        # Make `NUM_IMAGES_PER_PROMPT` requests to the endpoint at once!\n",
    "        images = ray.get(\n",
    "            [generate_image.remote(prompt) for _ in range(NUM_IMAGES_PER_PROMPT)]\n",
    "        )\n",
    "\n",
    "        dirname = f\"{uuid.uuid4().hex[:8]}\"\n",
    "        os.makedirs(dirname)\n",
    "        filenames = []\n",
    "        for i, image in enumerate(images):\n",
    "            filename = os.path.join(dirname, f\"{i}.png\")\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(image)\n",
    "            filenames.append(filename)\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        generation_times.append(elapsed)\n",
    "        print(\n",
    "            f\"\\nGenerated {len(images)} image(s) in {elapsed:.2f} seconds to \"\n",
    "            f\"the directory: {dirname}\\n\"\n",
    "        )\n",
    "        show_images(filenames)\n",
    "        if not INTERACTIVE:\n",
    "            break\n",
    "    return np.mean(generation_times) if generation_times else -1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8949cc7",
   "metadata": {},
   "source": [
    "Once the stable diffusion model finishes generating your image(s), it will be included in the HTTP response body.\n",
    "The client saves all the images in a local directory for you to view, and they'll also show up in the notebook cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_generation_time = main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb124968",
   "metadata": {},
   "source": [
    "You've successfully served a stable diffusion model!\n",
    "You can modify this template and iterate your model deployment directly on your cluster within your Anyscale Workspace,\n",
    "testing with the local endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e360cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the model replicas once you're done!\n",
    "serve.shutdown()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "880c2d6f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This template used [Ray Serve](https://docs.ray.io/en/latest/serve/index.html) to serve many replicas of a stable diffusion model. Ray Serve is one of many libraries under the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html).\n",
    "\n",
    "At a high level, this template showed how to:\n",
    "1. Define a Ray Serve deployment to load a HuggingFace model and perform inference.\n",
    "2. Set up a local endpoint to accept and route requests to the different model replicas.\n",
    "3. Make multiple requests in parallel to generate many images at a time.\n",
    "\n",
    "See this [getting started guide](https://docs.ray.io/en/latest/serve/getting_started.html) for a more detailed walkthrough of Ray Serve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc69b2d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray_dev_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "265d195fda5292fe8f69c6e37c435a5634a1ed3b6799724e66a975f68fa21517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
